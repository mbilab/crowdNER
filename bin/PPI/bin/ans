#!/usr/local/bin/lsc

require! <[edit-google-spreadsheet fs ../../../lib/crowd.ls]>

#### global variables (with default values)

opt =
  blacklist: []
  code: event: 2 ignored: 0 normal: -1 protein: 1
  debug: true
  fixed-supp: false
  google: JSON.parse fs.read-file-sync \../../../option.json \utf-8 .google
  max-tops: 30
  min-freq: 5
  min-supp: 3
  path: res: \../res src: \../src
  theme: \NER
<<< require \node-getopt .create [
  * [\a , \action=ARG     , 'specify operation']
  * [\b , \blacklist=ARG+ , 'push subject id in blacklist']
  * [\f , \minFreq=ARG    , 'set minimum threshold of word frequency in each article to be extracted']
  * [\F , \fixedSupp      , 'set for integrating results exactly satisfy the required support (default: more than minimum support)']
  * [\h , \help           , 'show this help']
  * [\t , \maxTops=ARG    , 'set maximum amounts of top frequent words in each article to be extracted']
  * [\T , \theme=ARG      , "specify theme (default: `#{opt.theme}`)"]
] .bind-help '\nUsage: lsc ans.ls\n[[OPTIONS]]\n' .parse-system!options

res =
  adm: JSON.parse fs.read-file-sync "#{opt.path.res}/words/academicWords.json" \utf-8
  NER: JSON.parse fs.read-file-sync "#{opt.path.res}/words/bioEntity.json" \utf-8
  nor: JSON.parse fs.read-file-sync "#{opt.path.res}/words/normalWord.json" \utf-8

#### utility

!function ERR then throw it

#######################################################################################

switch opt.action
| \build-ans

  # build answers for NER only; specify operation as `parse-checked-words` to get additional PPI answers

  gs-answer = if fs.exists-sync "#{opt.path.res}/gs-answer.json" then JSON.parse fs.read-file-sync "#{opt.path.res}/gs-answer.json" \utf-8 else box1: {}
  ignored-entity = "(#{JSON.parse fs.read-file-sync "#{opt.path.res}/words/ignored.json" \utf-8 .join \|})"

  for pmid in fs.readdir-sync "#{opt.path.res}/world/box"
    art = JSON.parse fs.read-file-sync "#{opt.path.res}/world/box/#pmid" \utf-8
    ans = gs-answer.box1[pmid] ?= {}

    for stc, stcid in art.word
      stc-ans = ans[stcid] ?= {}

      for word, wid in stc
        if word.match ignored-entity
          stc-ans[wid] = opt.code.ignored
        else if res.NER.named-entity.protein[word]
          stc-ans[wid] = opt.code.protein
        else if not stc-ans[wid]
          stc-ans[wid] = opt.code.normal

  fs.write-file-sync "#{opt.path.res}/gs-answer.json" JSON.stringify gs-answer, null 2

| \build-pending-words
  return ERR 'Error input: amounts of top frequent words' if not (opt.max-tops = parseInt opt.max-tops)
  return ERR 'Error input: threshold of word frequency' if not (opt.min-freq = parseInt opt.min-freq)

  word-checked = JSON.parse JSON.stringify res.nor
  word-checked <<< res.NER.category
  Object.keys res.NER.named-entity .map !-> word-checked <<< res.NER.named-entity[it]
  Object.keys res.adm .map (field) !-> Object.keys res.adm[field] .map !-> word-checked <<< res.adm[field][it]
  words-freq = JSON.parse fs.read-file-sync "#{opt.path.res}/world/wordsFreq.json" \utf-8

  for pmid, words of words-freq.box1
    art = JSON.parse fs.read-file-sync "#{opt.path.res}/world/box/#pmid" \utf-8
    md-NER = "mia NER_#pmid\n===\n\n## #pmid\n"
    md-PPI = "mia PPI_#pmid\n===\n\n## #pmid\n"
    word-counts = 0

    for i til words.length

      # top unchecked words for NER

      if not word-checked[words[i].word] and words[i].frequency >= opt.min-freq and ++word-counts <= opt.max-tops
        md-NER += "\n### #{words[i].word} (frequency: #{words[i].frequency})\n\n"
        for stcid of words[i].stcid
          md-NER += '- [ ]'
          for w, wid in art.word[stcid]
            md-NER += if w is words[i].word then "<span style='background-color: pink;'>#w</span>" else w
            md-NER += art.nonword[stcid][wid]
          md-NER += " [stcid: #stcid]\n"

      # top entity pairs for PPI

      continue if not res.NER.named-entity.protein[words[i].word]

      for j from i + 1 til words.length
        continue if not res.NER.named-entity.protein[words[j].word]

        md-PPI += "\n### #{words[i].word}_#{words[j].word}\n\n"
        for stcid of words[i].stcid
          continue if not words[j].stcid[stcid]

          md-PPI += '- [ ]'
          for w, wid in art.word[stcid]
            md-PPI += if w is words[i].word or w is words[j].word then "<span style='background-color: pink;'>#w</span>" else w
            md-PPI += art.nonword[stcid][wid]
          md-PPI += " [stcid: #stcid]\n"

    fs.write-file-sync "#{opt.path.src}/words/pending/NER_#pmid.md" md-NER
    fs.write-file-sync "#{opt.path.src}/words/pending/PPI_#pmid.md" md-PPI

| \parse-checked-words
  gs-answer = if fs.exists-sync "#{opt.path.res}/gs-answer.json" then JSON.parse fs.read-file-sync "#{opt.path.res}/gs-answer.json" \utf-8 else box1: {}
  ignored-entity = "(#{JSON.parse fs.read-file-sync "#{opt.path.res}/words/ignored.json" \utf-8 .join \|})"

  for md in fs.readdir-sync "#{opt.path.src}/words/checked/"
    if /^NER/ is md
      for item in fs.read-file-sync "#{opt.path.src}/words/checked/#md" \utf-8 .match /###.*/g
        word = item.match /###\s(.+?)\s/ .1
        if /{(.+)}/ is item then (that.1 / ', ').map -> res.NER.named-entity[it][word] = true
        else                     res.nor[word] = true

    else if /^PPI/ is md
      md = fs.read-file-sync "#{opt.path.src}/words/checked/#md" \utf-8
      art = JSON.parse fs.read-file-sync "#{opt.path.res}/world/box/#{pmid = md.match /##\s(\d+)\n/ .1}" \utf-8
      ans = gs-answer.box1[pmid] ?= {}

      for stc in md.match /- \[[x\s]\].*\n/g
        stc-ans = ans[stcid = stc.match /\[stcid:\s(\d+)\]/ .1] ?= {}

        if stc.match /<span style='background-color: lightblue;'>.+?<\/span>/g
          event-wrds = "(#{that.map(-> it = it.match />(.+)</ .1.replace(/\s/g, \|)) * \|})"
        else
          event-wrds = ''

        for word, wid in art.word[stcid]
          if word.match ignored-entity
            stc-ans[wid] = opt.code.ignored
          else if res.NER.named-entity.protein[word]
            stc-ans[wid] = opt.code.protein
          else if '' isnt event-wrds and word.match event-wrds
            stc-ans[wid] = opt.code.event
          else if not stc-ans[wid]
            stc-ans[wid] = opt.code.normal

  fs.write-file-sync "#{opt.path.res}/words/bioEntity.json" JSON.stringify res.NER, null 2
  fs.write-file-sync "#{opt.path.res}/words/normalWord.json" JSON.stringify res.nor, null 2
  fs.write-file-sync "#{opt.path.res}/gs-answer.json" JSON.stringify gs-answer, null 2

| \parse-mark-result
  subject = JSON.parse fs.read-file-sync "#{opt.path.res}/world/subject.json" \utf-8
  blacklist = "^(#{opt.blacklist.map(-> subject.personal[it].expID * \|) * \|})$"

  art = {}; refined-art = {}
  for pmid in fs.readdir-sync "#{opt.path.res}/world/box/"
    art[pmid] = JSON.parse fs.read-file-sync "#{opt.path.src}/box/box1/#pmid" \utf-8
    refined-art[pmid] = JSON.parse fs.read-file-sync "#{opt.path.res}/world/box/#pmid" \utf-8

  mark-result = {}
  for labeler-group in <[expert subject]>

    for log-id in fs.readdir-sync "#{opt.path.src}/mark-result/#labeler-group"
      continue if opt.blacklist.length and log-id.match blacklist

      elapsed-time = 0; last-submit-time = null

      for log in (fs.read-file-sync("#{opt.path.src}/mark-result/#labeler-group/#log-id" \utf-8) / \\n).slice 0 -1
        log = JSON.parse log

        curr-submit-time = new Date(log.time) / 1000
        elapsed-time = curr-submit-time - last-submit-time if last-submit-time
        last-submit-time = curr-submit-time

        continue if \submit isnt log.action or 1 isnt log.box

        _box = mark-result["box#{log.box}"] ?= {}
        _group = _box[labeler-group] ?= {}
        _labeler = _group[log-id] ?= {}
        _art = _labeler[log.pmid] ?= {}
        stc = _art[log.stcid] ?= elapsed-time: elapsed-time, event: {}, protein: {}

        for word-type in <[event protein]>
          for wid in log[word-type]
            wid = parseInt wid
            flag = false

            for i til art[log.pmid].word[log.stcid].length
              if art[log.pmid].word[log.stcid][wid] is refined-art[log.pmid].word[log.stcid][wid - i]
                stc[word-type][wid - i] = true
              else if art[log.pmid].word[log.stcid][wid] is refined-art[log.pmid].word[log.stcid][wid + i]
                stc[word-type][wid + i] = true
              else if refined-art[log.pmid].word[log.stcid][wid - i] and refined-art[log.pmid].word[log.stcid][wid - i].match art[log.pmid].word[log.stcid][wid]
                stc[word-type][wid - i] = true
              else if refined-art[log.pmid].word[log.stcid][wid + i] and refined-art[log.pmid].word[log.stcid][wid + i].match art[log.pmid].word[log.stcid][wid]
                stc[word-type][wid + i] = true
              else continue

              flag = true
              break

            console.log art[log.pmid].word[log.stcid][wid] if not flag

  # sentences labeled by subjects

  mark-result.box1.labeled-stc = {}

  for subject-id, mark-rlt of mark-result.box1.subject
    for pmid, stcs of mark-rlt
      _art = mark-result.box1.labeled-stc[pmid] ?= {}

      for stcid, stc of stcs
        _stc = _art[stcid] ?= labeler: {} labels: {} supp: 0
        _stc.labeler[subject-id] = true
        _stc.supp++

        for word-type in <[event protein]>
          for wid of stc[word-type]
            w = _stc.labels[wid] ?= event: 0 protein: 0
            w[word-type]++

  fs.write-file-sync "#{opt.path.res}/mark-result.json" JSON.stringify mark-result, null 2

| \sentence-resplit

  # re-split words of each sentence with new regex rule

  special-char = JSON.parse fs.read-file-sync "#{opt.path.src}/words/specialChar.json" \utf-8
  stop-words = JSON.parse fs.read-file-sync "#{opt.path.src}/words/stopWords.json" \utf-8
  words = box1: {}

  for pmid in fs.readdir-sync "#{opt.path.src}/box/box1" .filter(-> /^\d+$/ is it)
    refined-art = (JSON.parse JSON.stringify (art = JSON.parse fs.read-file-sync "#{opt.path.src}/box/box1/#pmid" \utf-8)) <<< nonword: [] word: []
    art-words = {}

    for stc, stcid in art.context
      if stc.match /(&#x[\da-f]{5};)/g
        checked-symbols = {}

        for symbol in that
          continue if checked-symbols[symbol]

          stc = stc.replace new RegExp(symbol, \g), special-char[symbol].character
          checked-symbols[symbol] = true

      refined-art.nonword[stcid] = []
      refined-art.word[stcid] = []

      for w, wid in stc.split /(&thinsp;|\s[-–]\s|[^\wαβγµáéκμνσΔ°–−-]+)/ .slice 0 -1
        if wid % 2
          refined-art.nonword[stcid].push w
        else
          refined-art.word[stcid].push w
          continue if stop-words[w]

          word = art-words[w] ?= frequency: 0 stcid: {}
          word.frequency++
          word.stcid[stcid] = true
    words.box1[pmid] = [{word: ..} <<< art-words[..] for Object.keys(art-words).sort (a, b) -> art-words[b].frequency - art-words[a].frequency]

    fs.write-file-sync "#{opt.path.res}/world/box/#pmid" JSON.stringify refined-art, null 2

  fs.write-file-sync "#{opt.path.res}/world/wordsFreq.json" JSON.stringify words, null 2

| \show-labeled-result
  gs-answer = JSON.parse fs.read-file-sync "#{opt.path.res}/gs-answer.json" \utf-8
  mark-result = JSON.parse fs.read-file-sync "#{opt.path.res}/mark-result.json" \utf-8

  html = "<html><head><meta charset='utf-8'></head><body>"

  for pmid in fs.readdir-sync "#{opt.path.res}/world/box"
    art = JSON.parse fs.read-file-sync "#{opt.path.res}/world/box/#pmid" \utf-8

    for stc, stcid in art.word
      continue if not mark-result.box1.labeled-stc[pmid][stcid] or mark-result.box1.labeled-stc[pmid][stcid].supp < opt.min-supp

      ans = ''; rlt = ''
      show-stc = false # show sentences with different label result between gs-answer and mark-result only
      for word, wid in stc
        if opt.code.event is gs-answer.box1[pmid][stcid][wid]
          ans += "<span style='background-color: lightblue'>#word</span> (#wid)"
        else if opt.code.protein is gs-answer.box1[pmid][stcid][wid]
          ans += "<span style='background-color: pink'>#word</span> (#wid)"
        else if opt.code.ignored is gs-answer.box1[pmid][stcid][wid]
          ans += "<span style='background-color: lightgreen'>#word</span> (#wid)"
        else
          ans += "#word (#wid)"

        if mark-result.box1.labeled-stc[pmid][stcid].labels[wid]
          if mark-result.box1.labeled-stc[pmid][stcid].labels[wid].event > mark-result.box1.labeled-stc[pmid][stcid].labels[wid].protein
            rlt += "<span style='background-color: lightblue'>#word</span> (#wid)"
            show-stc = true if opt.code.event isnt gs-answer.box1[pmid][stcid][wid]
          else if mark-result.box1.labeled-stc[pmid][stcid].labels[wid].event < mark-result.box1.labeled-stc[pmid][stcid].labels[wid].protein
            rlt += "<span style='background-color: pink'>#word</span> (#wid)"
            show-stc = true if opt.code.protein isnt gs-answer.box1[pmid][stcid][wid]
          else
            rlt += "#word (#wid)"
            show-stc = true if opt.code.ignored isnt gs-answer.box1[pmid][stcid][wid] and opt.code.normal isnt gs-answer.box1[pmid][stcid][wid]
        else
          rlt += "#word (#wid)"
          show-stc = true if opt.code.ignored isnt gs-answer.box1[pmid][stcid][wid] and opt.code.normal isnt gs-answer.box1[pmid][stcid][wid]

        ans += art.nonword[stcid][wid]
        rlt += art.nonword[stcid][wid]

      html += "<h2>#pmid [stcid: #stcid]</h2><div>#ans</div><br/><div>#rlt</div>" if show-stc

  html += '</body></html>'

  fs.write-file-sync "#{opt.path.res}/labeled-result.html" html

| \verify

  # compare mark-result with gs-answer and show statistic data on google spreadsheet

  gs-answer = JSON.parse fs.read-file-sync "#{opt.path.res}/gs-answer.json" \utf-8
  mark-result = JSON.parse fs.read-file-sync "#{opt.path.res}/mark-result.json" \utf-8
  stc-value = JSON.parse fs.read-file-sync "#{opt.path.res}/world/stcValue.json" \utf-8
  subject = JSON.parse fs.read-file-sync "#{opt.path.res}/world/subject.json" \utf-8
  verify-rlt = if fs.exists-sync "#{opt.path.res}/verify/#{opt.theme}/verification.json" then JSON.parse fs.read-file-sync "#{opt.path.res}/verify/#{opt.theme}/verification.json" \utf-8 else crowd-sourcing: {} experts: {} subjects: {}

  integrate = if opt.fixed-supp then crowd.integrate-fixed else crowd.integrate-exceeded # integrating type

  app =
    col-id: subject-id: 1 department: 2 degree: 3 grade: 4 submits: 5 tp: 6 fp: 7 fn: 8 tn: 9 accuracy: 10 recall: 11 precision: 12 f-score: 13
    max-considered-conf: 1 max-considered-supp: 15 row-id: 6 separated-rows-between-blocks: 3
  stats = {}

  (err, sheet) <-! edit-google-spreadsheet.load {opt.debug} <<< oauth2: opt.google.oauth2, spreadsheet-id: opt.google.spreadsheet-id, worksheet-id: opt.google.worksheet.stats
  return ERR 'Failed as loading to google spreadsheet' if err

  # verification of individual expert

  for expert-id of mark-result.box1.expert
    crowd.verify opt.theme, gs-answer.box1, mark-result.box1.expert[expert-id], rlt = submits: 0 tp: 0 fp: 0 fn: 0 tn: 0
    rlt.acc = (rlt.tp + rlt.tn) / (rlt.tp + rlt.fp + rlt.fn + rlt.tn)
    rlt.pre = rlt.tp / (rlt.tp + rlt.fp)
    rlt.rec = rlt.tp / (rlt.tp + rlt.fn)
    rlt.f-score = 2 * rlt.pre * rlt.rec / (rlt.pre + rlt.rec)

    stats[app.row-id++] =
      "#{app.col-id.subject-id}": expert-id
      "#{app.col-id.submits}"   : rlt.submits
      "#{app.col-id.tp}"        : rlt.tp
      "#{app.col-id.fp}"        : rlt.fp
      "#{app.col-id.fn}"        : rlt.fn
      "#{app.col-id.tn}"        : rlt.tn
      "#{app.col-id.accuracy}"  : rlt.acc
      "#{app.col-id.recall}"    : rlt.rec
      "#{app.col-id.precision}" : rlt.pre
      "#{app.col-id.f-score}"   : rlt.f-score

    verify-rlt.experts[expert-id] = rlt

  app.row-id += app.separated-rows-between-blocks

  # verification of individual subject

  blacklist = "^(#{opt.blacklist * \|})$"

  for degree in <[Bachelor Master Doctor Assistant]>
    for subject-id in subject.sort-by-degree[degree]
      continue if opt.blacklist.length and subject-id.match blacklist

      rlt = submits: 0 tp: 0 fp: 0 fn: 0 tn: 0
      subject.personal[subject-id].expID.map -> crowd.verify opt.theme, gs-answer.box1, mark-result.box1.subject[it], rlt
      rlt.acc = (rlt.tp + rlt.tn) / (rlt.tp + rlt.fp + rlt.fn + rlt.tn)
      rlt.pre = rlt.tp / (rlt.tp + rlt.fp)
      rlt.rec = rlt.tp / (rlt.tp + rlt.fn)
      rlt.f-score = 2 * rlt.pre * rlt.rec / (rlt.pre + rlt.rec)

      stats[app.row-id++] =
        "#{app.col-id.subject-id}": subject-id
        "#{app.col-id.department}": subject.personal[subject-id].department
        "#{app.col-id.degree}"    : subject.personal[subject-id].degree
        "#{app.col-id.grade}"     : subject.personal[subject-id].grade || ''
        "#{app.col-id.submits}"   : rlt.submits
        "#{app.col-id.tp}"        : rlt.tp
        "#{app.col-id.fp}"        : rlt.fp
        "#{app.col-id.fn}"        : rlt.fn
        "#{app.col-id.tn}"        : rlt.tn
        "#{app.col-id.accuracy}"  : rlt.acc
        "#{app.col-id.recall}"    : rlt.rec
        "#{app.col-id.precision}" : rlt.pre
        "#{app.col-id.f-score}"   : rlt.f-score

      verify-rlt.subjects[subject-id] = rlt <<< personal: subject.personal[subject-id]

  app.row-id += app.separated-rows-between-blocks

  # verification of integrated mark-result

  _verify-rlts = {}
  for min-supp from 1 to app.max-considered-supp
    _verify-rlts[min-supp] = {}
    verify-rlt.crowd-sourcing[min-supp] = {}

    for min-conf from 0.3 to app.max-considered-conf by 0.1
      rlt = _verify-rlts[min-supp][min-conf.to-fixed 1] = submits: 0 tp: 0 fp: 0 fn: 0 tn: 0 stc: total: 0 val_0: 0 val_1: 0 val_2: 0
      mark-rlt = integrate opt.theme, stc-value, min-supp, min-conf, mark-result.box1.labeled-stc, rlt

      crowd.verify opt.theme, gs-answer.box1, mark-rlt, rlt
      rlt.pre = rlt.tp / (rlt.tp + rlt.fp)
      rlt.rec = rlt.tp / (rlt.tp + rlt.fn)
      rlt.f-score = 2 * rlt.pre * rlt.rec / (rlt.pre + rlt.rec)

      verify-rlt.crowd-sourcing[min-supp][min-conf.to-fixed 1] = rlt

  for statistics in <[pre rec fScore]>
    for min-supp from 1 to app.max-considered-supp
      stats[++app.row-id] =
        '1': min-supp
        '2': _verify-rlts[min-supp]['0.3'].stc.total
        '3': _verify-rlts[min-supp]['0.3'].stc.val_0
        '4': _verify-rlts[min-supp]['0.3'].stc.val_1
        '5': _verify-rlts[min-supp]['0.3'].stc.val_2

      col-id = 6
      for min-conf from 0.3 to app.max-considered-conf by 0.1
        stats[app.row-id][col-id++] = _verify-rlts[min-supp][min-conf.to-fixed 1][statistics]
    app.row-id += 14 # empty rows for showing charts

  fs.write-file-sync "#{opt.path.res}/verify/#{opt.theme}/verification.json" JSON.stringify verify-rlt, null 2

  sheet.add stats; sheet.send !-> return ERR 'Failed as updating google spreadsheet' if it

| _ then ERR 'No corresponding operation'

# vi:et:ft=ls
